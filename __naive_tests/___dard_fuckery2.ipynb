{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from copy import deepcopy\n",
    "from distance import canon\n",
    "from _types import Reward\n",
    "from env import Env, RandomEnv\n",
    "from coverage_dist import get_state_dist, get_action_dist\n",
    "from reward import random_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_dard(reward: Reward, env: Env):\n",
    "  D_a = get_action_dist(env)\n",
    "\n",
    "  term1 = np.zeros((1, 1, env.n_s))\n",
    "  for s_prime in range(env.n_s):\n",
    "    for A, A_prob in enumerate(D_a):\n",
    "      for S_double, S_double_prob in enumerate(env.transition_dist[s_prime, A, :]):\n",
    "        prob = A_prob * S_double_prob\n",
    "        term1[0, 0, s_prime] += prob * env.discount * reward[s_prime, A, S_double]\n",
    "  \n",
    "  term2 = np.zeros((env.n_s, 1, 1))\n",
    "  for s in range(env.n_s):\n",
    "    for A, A_prob in enumerate(D_a):\n",
    "      for S_prime, S_prime_prob in enumerate(env.transition_dist[s, A, :]):\n",
    "        prob = A_prob * S_prime_prob\n",
    "        term2[s, 0, 0] += prob * reward[s, A, S_prime]\n",
    "  \n",
    "  term3 = np.zeros((env.n_s, 1, env.n_s))\n",
    "  for s in range(env.n_s):\n",
    "    for s_prime in range(env.n_s):\n",
    "      for A, A_prob in enumerate(D_a):\n",
    "        for S_prime, S_prime_prob in enumerate(env.transition_dist[s, A, :]):\n",
    "          for S_double, S_double_prob in enumerate(env.transition_dist[s_prime, A, :]):\n",
    "            prob = A_prob * S_prime_prob * S_double_prob\n",
    "            term3[s, 0, s_prime] += prob * env.discount * reward[S_prime, A, S_double]\n",
    "  \n",
    "  return term1, term2, term3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dard_brr(reward: Reward, env: Env):\n",
    "  A = get_action_dist(env)\n",
    "\n",
    "  potential = (env.transition_dist * reward).sum(axis=2)\n",
    "  potential = (potential * A[None, :]).sum(axis=1)\n",
    "\n",
    "  term1 = env.discount * potential[None, None, :]\n",
    "  term2 = potential[:, None, None]\n",
    "  \n",
    "  joint_probs = ( # [s, s', S', A, S'']; p(S', S'' | s, s', A=A)\n",
    "    A[None, None, None, :, None] * \n",
    "    rearrange(env.transition_dist, 's A Sp -> s 1 Sp A 1') *\n",
    "    rearrange(env.transition_dist, 'sp A Sd -> 1 sp 1 A Sd')\n",
    "  )\n",
    "  r_given_probs = reward[None, None, ...] * joint_probs\n",
    "  term3 = env.discount * r_given_probs.sum(axis=(2,3,4))[:,None,:]\n",
    "  \n",
    "  return term1, term2, term3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "  e = RandomEnv(8, 2)\n",
    "  r = random_reward(e)\n",
    "  s1, s2, s3 = slow_dard(r, e)\n",
    "  b1, b2, b3 = dard_brr(r, e)\n",
    "  assert np.isclose(s1, b1).all()\n",
    "  assert np.isclose(s2, b2).all()\n",
    "  assert np.isclose(s3, b3).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "178f5955e7ec2db83c487531b6f19a6ba078d2c9bcad0eaf79872b0fcb34bd80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
